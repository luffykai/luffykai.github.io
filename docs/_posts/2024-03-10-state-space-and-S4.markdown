
Recently [Mamba](https://arxiv.org/ftp/arxiv/papers/2312/2312.00752.pdf) got a lot of attentions as a non-attention model. 
It's built upon and long series of work on the state space model.
My [heptabase reading note](https://app.heptabase.com/w/088cab4fc0272389c519d4df33f04134e28af8840e0f299ffda3866df2e8457d).
(not even started on mamba, only S4 stuffs now)

Reference:
- [S4 paper](https://arxiv.org/pdf/2111.00396.pdf)
- [annotated S4](https://srush.github.io/annotated-s4/)